# -----------------------------------------------------------------------------
# íŒŒì¼ëª… : log_gateway/pipeline.py
# ëª©ì    : ì„œë¹„ìŠ¤ë³„ ë°°ì¹˜ ìƒì„± ë£¨í”„ ë° Kafka í¼ë¸”ë¦¬ì…” íƒœìŠ¤í¬ êµ¬ì„±
# ì„¤ëª…   : generatorê°€ ì „ë‹¬í•œ í”„ë¡œíŒŒì¼/ì‹œë®¬ë ˆì´í„° ê¸°ë°˜ìœ¼ë¡œ í+ì›Œì»¤ íë¦„ì„ ì‹¤í–‰
# -----------------------------------------------------------------------------
from __future__ import annotations

import asyncio
import random
import time
from typing import Any, Dict, List, Tuple

from .producer import publish, get_producer
from .config.stats import record_tps
from .config.timeband import current_hour_kst, pick_multiplier

# ===== íŒŒì´í”„ë¼ì¸(ìƒì„±/ì „ì†¡) íŒŒë¼ë¯¸í„° =====
# BATCH_MIN : int = 300
# BATCH_MAX : int = 600
LOG_BATCH_SIZE : int = 300
QUEUE_SIZE : int = 10000
PUBLISHER_WORKERS : int = 8
WORKER_BATCH_SIZE : int = 800

# # í¼ë¸”ë¦¬ì…” íŠœë‹(ë¯¸ë‹ˆë°°ì¹˜ ë“œë ˆì¸/í´ë§/ë°±ì˜¤í”„)
# WORKER_DRAIN_COUNT: int = int(os.getenv("LG_WORKER_DRAIN_COUNT", "5000"))
# WORKER_DRAIN_MS: int = int(os.getenv("LG_WORKER_DRAIN_MS", "5"))
# POLL_EVERY: int = int(os.getenv("LG_POLL_EVERY", "1000"))
# BUFFER_BACKOFF_MS: int = int(os.getenv("LG_BUFFER_BACKOFF_MS", "5"))


async def _service_stream_loop(
    service: str,
    simulator: Any,
    target_rps: float,
    publish_queue: "asyncio.Queue[Tuple[str, str, bool]]",
    bands: List[Any],
    weight_mode: str,
    # batch_range: Tuple[int, int],
    log_batch_size: int
) -> None:
    """ì„œë¹„ìŠ¤ë³„ë¡œ ë°°ì¹˜ ë¡œê·¸ë¥¼ ìƒì„±í•´ í¼ë¸”ë¦¬ì‹œ íì— ìŒ“ëŠ”ë‹¤."""
    # batch_min, batch_max = batch_range  # í”„ë¡œíŒŒì¼ê³¼ ë¬´ê´€í•˜ê²Œ ê³ ì •ëœ ë°°ì¹˜ ë²”ìœ„
    # batch_min = max(1, batch_min)
    # batch_max = max(batch_min, batch_max)

    while True:
        hour = current_hour_kst()  # í˜„ì¬ ì‹œê°„ëŒ€(KST) ê²°ì •
        multiplier = pick_multiplier(bands, hour_kst=hour, mode=weight_mode) if bands else 1.0  # ì‹œê°„ëŒ€ ê°€ì¤‘ì¹˜ ì ìš©
        effective_rps = max(target_rps * multiplier, 0.01)  # ëª©í‘œ RPS Ã— multiplier
        # log_batch_size = random.randint(batch_min, batch_max)  # ë°°ì¹˜ í¬ê¸°ë¥¼ ëœë¤ ì„ íƒ
        log_batch_size = log_batch_size

        logs = simulator.generate_logs(log_batch_size)  # ì‹œë®¬ë ˆì´í„°ì—ì„œ ë¡œê·¸ ë°°ì¹˜ ìƒì„±
        
        # 2025-12-07 ìˆ˜ì •
        # ë°°ì¹˜ë¡œ ë§Œë“  ë¡œê·¸ë¥¼ ë‹¤ì‹œ 1ê±´ ì”© render + queue.putì„ í•˜ëŠ” ì´ìŠˆ.
        # start = time.time()
        # for event in logs:
        #     payload = simulator.render(event)
        #     is_error = event.get("level") == "ERROR"
        #     record_tps(service)
        #     await publish_queue.put((service, payload, is_error))  # íì— (ì„œë¹„ìŠ¤, í˜ì´ë¡œë“œ, ì—ëŸ¬ì—¬ë¶€) push
        # print("old_put_time", time.time() - start)

        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        # start = time.time()

        payloads = [simulator.render(log) for log in logs] # ë°°ì¹˜ ë‹¨ìœ„ ë Œë”ë§
        await asyncio.gather(*[                            # ë°°ì¹˜ ë‹¨ìœ„ í ì‚½ì…
            publish_queue.put((service, payload, log.get("level") == "ERROR"))
            for payload, log in zip(payloads, logs)
        ])
        
        # print("new_put_time", time.time() - start)
        print("queue size:", publish_queue.qsize())
        
        sleep_time = log_batch_size / effective_rps  # ë°°ì¹˜ ì²˜ë¦¬ì— ì†Œë¹„í•´ì•¼ í•˜ëŠ” ì‹œê°„ â†’ ëª©í‘œ RPS ë§ì¶”ê¸° ìœ„í•¨

        print("target_rps:", effective_rps, "batch:", log_batch_size, "sleep_time:", sleep_time)

        if sleep_time > 0:
            await asyncio.sleep(sleep_time)


async def _publisher_worker(
    worker_id: int,
    publish_queue: "asyncio.Queue[Tuple[str, str, bool]]",
    stats_queue: "asyncio.Queue[Tuple[str, int]]",
) -> None:
    """íì— ìŒ“ì¸ ë¡œê·¸ë¥¼ Kafkaì— ë°œí–‰"""
    
    # ë³‘ëª© ë°œìƒ : event ë‹¨ìœ„ë¡œ ì²˜ë¦¬ ì›ì¸
    # while True:
    #     service, payload, is_error = await publish_queue.get()
    #     try:
    #         await producer.publish(service, payload, replicate_error=is_error)  # Kafka publish (ì—ëŸ¬ í† í”½ ë³µì œ í¬í•¨)
    #         # record_tps(service)  # kafka ë°œí–‰ tps ì¸¡ì •
    #         stats_queue.put_nowait((service, 1))  # í†µê³„ íì— ì²˜ë¦¬ ê±´ìˆ˜ ë³´ê³ 
    #     finally:
    #         publish_queue.task_done()
    while True:
        batch = []

        # ìµœì†Œ 1ê±´
        batch.append(await publish_queue.get())

        # WORKER_BATCH_SIZE-1ê°œ ì¶”ê°€ drain
        for _ in range(WORKER_BATCH_SIZE - 1):
            try:
                batch.append(publish_queue.get_nowait())
            except asyncio.QueueEmpty:
                break

        # ë³‘ë ¬ publish
        await asyncio.gather(*[
            publish(service, payload, None, err)
            for (service, payload, err) in batch
        ])

        producer = get_producer()
        producer.poll(0)

        # --- ğŸ”¥ ì„œë¹„ìŠ¤ë³„ ì¹´ìš´íŠ¸ ì§‘ê³„ ---
        svc_counter = {}
        for (svc, _, _) in batch:
            svc_counter[svc] = svc_counter.get(svc, 0) + 1

        # --- ğŸ”¥ stats_queueì— ì„œë¹„ìŠ¤ë³„ë¡œ push ---
        for svc, cnt in svc_counter.items():
            stats_queue.put_nowait((svc, cnt))

        # --- task_done ì²˜ë¦¬ ---
        for _ in batch:
            publish_queue.task_done()


def start_pipeline(
    simulators: Dict[str, Any],
    base_rps: float,
    bands: List[Any],
    service_rps: Dict[str, float],
    weight_mode: str,
) -> Tuple[
    "asyncio.Queue[Tuple[str, str, bool]]",
    "asyncio.Queue[Tuple[str, int]]",
    List[asyncio.Task],
    List[asyncio.Task],
]:
    """í/ì›Œì»¤ íƒœìŠ¤í¬ë¥¼ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜."""
    # batch_range = (BATCH_MIN, BATCH_MAX)
    log_batch_size = LOG_BATCH_SIZE
    publish_queue: "asyncio.Queue[Tuple[str, str, bool]]" = asyncio.Queue(maxsize=QUEUE_SIZE)  # Kafka ì „ì†¡ ëŒ€ê¸° í
    stats_queue: "asyncio.Queue[Tuple[str, int]]" = asyncio.Queue()  # RPS ê³„ì‚°ìš© í

    available_services = list(simulators.keys())
    service_count = max(len(available_services), 1)
    fallback_rps = base_rps / service_count  # mixì— ì—†ëŠ” ì„œë¹„ìŠ¤ ëŒ€ë¹„ ê¸°ë³¸ RPS

    service_tasks = [
        asyncio.create_task(
            _service_stream_loop(
                service=service,
                simulator=simulators[service],
                target_rps=service_rps.get(service, fallback_rps),
                publish_queue=publish_queue,
                bands=bands,
                weight_mode=weight_mode,
                # batch_range=batch_range,
                log_batch_size=log_batch_size,
            ),
            name=f"service-loop-{service}",
        )
        for service in available_services
    ]

    publisher_tasks = [
        asyncio.create_task(
            _publisher_worker(worker_id=i, publish_queue=publish_queue, stats_queue=stats_queue),
            name=f"publisher-{i}",
        )
        for i in range(PUBLISHER_WORKERS)
    ]

    return publish_queue, stats_queue, service_tasks, publisher_tasks
